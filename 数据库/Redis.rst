Redis
================

Redis概述
-----------------------
* Redis是一个开源的key-value存储系统。
* 和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）。
* 这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。
* 在此基础上，Redis支持各种不同方式的排序。
* 与memcached一样，为了保证效率，数据都是缓存在内存中。
* 区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。
* 并且在此基础上实现了master-slave(主从)同步。


应用场景
--------------------
1. 高频次，热门访问的数据，降低数据库IO
2. 分布式架构做session共享
3. 最新N个数据，通过List实现按自然时间排序的数据
4. 排行榜，TopN, 利用zset(有序集合)
5. 时效性的数据，比如手机验证码，通过expire实现
6. 计数器，秒杀，利用原子性，自增方法INCR,DECR
7. 去除大量数据中的重复数据，利用set
8. 构建队列，利用list集合
9. 发布订阅消息系统，pub/sub模式

Redis介绍相关知识
--------------------------
1. 默认16个数据库，类似数组下标从0开始，初始默认使用0号库
2. 使用命令 select   <dbid>来切换数据库。如: select 8 
3. 统一密码管理，所有库同样密码。
4. dbsize查看当前数据库的key的数量
5. flushdb清空当前库
6. flushall清空全部库
7. Redis是单线程+多路IO复用技术


五大数据类型
-----------------------

键(key)
`````````````
* keys   查看当前库所有key
* exists key判断某个key是否存在
* type key 查看你的key是什么类型
* del key       删除指定的key数据
* unlink key   根据value选择非阻塞删除，仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。
* expire key 10   10秒钟：为给定的key设置过期时间
* ttl key 查看还有多少秒过期，-1表示永不过期，-2表示已过期

字符串(String)
```````````````````````
String类型是二进制安全的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象。
String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是 **512M**   

* set   <key><value>添加键值对
  - NX：当数据库中key不存在时，可以将key-value添加数据库
  - XX：当数据库中key存在时，可以将key-value添加数据库，与NX参数互斥
  - EX：key的超时秒数
  - PX：key的超时毫秒数，与EX互斥

* get   <key>查询对应键值
* append  <key><value>将给定的<value> 追加到原值的末尾
* strlen  <key>获得值的长度
* setnx  <key><value>只有在 key 不存在时    设置 key 的值
* incr  <key> 将 key 中储存的数字值增1(原子操作),只能对数字值操作，如果为空，新增值为1
* decr  <key> 将 key 中储存的数字值减1(原子操作),只能对数字值操作，如果为空，新增值为-1
* incrby / decrby  <key><步长>将 key 中储存的数字值增减。自定义步长
* mset  <key1><value1><key2><value2>  .....  同时设置一个或多个 key-value对
* mget  <key1><key2><key3> ..... 同时获取一个或多个 value
* msetnx <key1><value1><key2><value2>  ..... 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。
  原子性，有一个失败则都失败
* getrange  <key><起始位置><结束位置> 获得值的范围，类似java中的substring，前包，后包
* setrange  <key><起始位置><value> 用 <value>  覆写<key>所储存的字符串值，从<起始位置>开始(索引从0开始)
* setex  <key><过期时间><value>  设置键值的同时，设置过期时间，单位秒。
* getset <key><value>  以新换旧，设置了新值同时获得旧值。

列表(List)
```````````````````
Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。

它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。

List的数据结构为快速链表quickList。

Redis将链表和ziplist结合起来组成了quicklist。
也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。

在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist,也即是压缩列表。

* lpush/rpush  <key><value1><value2><value3> .... 从左边/右边插入一个或多个值。
* lpop/rpop  <key>从左边/右边吐出一个值。值在键在，值光键亡。
* rpoplpush  <key1><key2>从<key1>列表右边吐出一个值，插到<key2>列表左边。
* lrange <key><start><stop> 按照索引下标获得元素(从左到右)
* lrange mylist 0 -1   0左边第一个，-1右边第一个，（0-1表示获取所有）
* lindex <key><index> 按照索引下标获得元素(从左到右)
* llen <key> 获得列表长度 
* linsert <key>  before <value> <newvalue> 在<value>的后面插入<newvalue>插入值
* lrem <key> <n> <value> 从左边删除n个value(从左到右)
* lset <key> <index> <value> 将列表key下标为index的值替换成value


集合(Set)
```````````````````
Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，
当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，
并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。

Set数据结构是dict字典，字典是用哈希表实现的。

* sadd <key><value1><value2> ..... 将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略
* smembers <key>取出该集合的所有值。
* sismember <key><value> 判断集合<key>是否为含有该<value>值，有1，没有0
* scard <key> 返回该集合的元素个数。
* srem <key><value1><value2> .... 删除集合中的某个元素。
* spop <key> 随机从该集合中吐出一个值。
* srandmember <key><n>随机从该集合中取出n个值。不会从集合中删除 。
* smove <source><destination>value 把集合中一个值从一个集合移动到另一个集合
* sinter <key1><key2>返回两个集合的交集元素。
* sunion <key1><key2>返回两个集合的并集元素。
* sdiff <key1><key2>返回两个集合的差集元素(key1中的，不包含key2中的)

哈希(Hash)
`````````````````````
Redis hash 是一个键值对集合。hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。
类似Java里面的Map<String,Object>

Hash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。
当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable。


* hset <key><field><value>给<key>集合中的  <field>键赋值<value>
* hget <key1><field>从<key1>集合<field>取出 value 
* hmset <key1><field1><value1><field2><value2>... 批量设置hash的值
* hexists <key1> <field>查看哈希表 key 中，给定域 field 是否存在。 
* hkeys <key> 列出该hash集合的所有field
* hvals <key> 列出该hash集合的所有value
* hincrby <key> <field> <increment>为哈希表 key 中的域 field 的值加上增量 1   -1
* hsetnx <key> <field> <value>将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在


有序集合Zset(sorted set) 
`````````````````````````````````
Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。

不同之处是有序集合的每个成员都关联了一个评分（score）,
这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。
集合的成员是唯一的，但是评分可以是重复了 。

因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。
访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。

zset底层使用了两个数据结构:

1. hash，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。
2. 跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。


* zadd  <key><score1><value1><score2><value2>… 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。
* zrange <key><start><stop>  [WITHSCORES]
  返回有序集 key 中，下标在<start><stop>之间的元素,带WITHSCORES，可以让分数一起和值返回到结果集。
* zrangebyscore key minmax [withscores] [limit offset count]
  返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 
* zrevrangebyscore key maxmin [withscores] [limit offset count]  同上，改为从大到小排列。 
* zincrby <key><increment><value>      为元素的score加上增量
* zrem  <key><value>删除该集合下，指定值的元素 
* zcount <key><min><max>统计该集合，分数区间内的元素个数 
* zrank <key><value>返回该值在集合中的排名，从0开始。

案例：如何利用zset实现一个文章访问量的排行榜？


Bitmaps
`````````````````
现代计算机用二进制（位） 作为信息的基础单位， 1个字节等于8位， 
例如“abc”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， 
“abc”分别对应的ASCII码分别是97、 98、 99， 对应的二进制分别是01100001、 01100010和01100011

合理地使用操作位能够有效地提高内存使用率和开发效率。
Redis提供了Bitmaps这个“数据类型”可以实现对位的操作：

1. Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。
2. Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 
   可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。

* setbit <key> <offset> <value> 设置Bitmaps中某个偏移量的值（0或1），offset:偏移量从0开始
* getbit <key> <offset> 获取Bitmaps中某个偏移量的值
* bitcount <key> [start end] 统计字符串从start字节到end字节比特值为1的数量，end可以使用负值
* bitop  and(or/not/xor) <destkey> [key…] bitop是一个复合操作， 它可以做多个Bitmaps的and（交集）,or（并集）,not（非）,xor（异或） 操作并将结果保存在destkey中

案例： 每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id。


地理信息(Geospatial)
`````````````````````````````````
Redis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。
该类型，就是元素的2维坐标，在地图上就是经纬度。
redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。

* geoadd<key>< longitude><latitude><member> [longitude latitude member...]   添加地理位置（经度，纬度，名称）。
  geoadd china:city 121.47 31.23 shanghai
* geopos  <key><member> [member...]  获得指定地区的坐标值
* geodist<key><member1><member2>  [m|km|ft|mi ]  获取两个位置之间的直线距离
* georadius<key>< longitude><latitude>radius  m|km|ft|mi   以给定的经纬度为中心，找出某一半径内的元素


Redis的发布和订阅
--------------------------
Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。
Redis 客户端可以订阅任意数量的频道。

* 客户端可以订阅频道
* 当给这个频道发布消息后，消息就会发送给订阅的客户端

1. 打开一个客户端订阅channel1,命令：SUBSCRIBE channel1
2. 打开另一个客户端，给channel1发布消息hello，命令：publish channel1 hello
3. 打开第一个客户端可以看到发送的消息


事务_锁机制
-------------------------
Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。
事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

Redis事务的主要作用就是串联多个命令防止别的命令插队。

主要使用三个命令：Multi、Exec、discard

从输入Multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。
组队的过程中可以通过discard来放弃组队。

事务的错误处理
`````````````````````
组队过程中某个命令出现了报告错误，执行时整个的所有队列都会被取消。

如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。

悲观锁
```````````````
悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，
所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。
传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

乐观锁
`````````````````
乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，
所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。
乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis就是利用这种check-and-set机制实现事务的。

watch
`````````````
* 在执行multi之前，先执行watch key1 [key2],可以监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。
* unwatch 取消 WATCH 命令对所有 key 的监视。如果在执行 WATCH 命令之后，EXEC 命令或DISCARD 命令先被执行了的话，那么就不需要再执行UNWATCH 了。

事务三特性
`````````````````
* 单独的隔离操作 
  - 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 

* 没有隔离级别的概念 
  - 队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行

* 不保证原子性 
  - 事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 


Redis持久化
---------------------
Redis 提供了2个不同形式的持久化方式。

* RDB（Redis DataBase）
* AOF（Append Of File）

RDB
`````````
在指定的时间间隔内将内存中的数据集快照写入磁盘， 也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里

备份是如何执行的?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到 一个临时文件中，
待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 
整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能 如果需要进行大规模数据的恢复，
且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。

在redis.conf中配置文件名称，持久化文件名默认为dump.rdb

* save ：save时只管保存，其它不管，全部阻塞。手动保存。不建议。
* bgsave：Redis会在后台异步进行快照操作， 快照同时还可以响应客户端请求。
* flushall命令，也会产生dump.rdb文件，但里面是空的，无意义

优势
~~~~~~~~~~~~~~~~~~~
* 适合大规模的数据恢复
* 对数据完整性和一致性要求不高更适合使用
* 节省磁盘空间
* 恢复速度快

劣势
~~~~~~~~~~~~~~~~~~~~~
* Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑
* 虽然Redis在fork时使用了写时拷贝技术,但是如果数据庞大时还是比较消耗性能。
* 在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。

AOF
```````
以日志的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来(读操作不记录)， 
只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，
redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作

AOF持久化流程:

1. 客户端的请求写命令会被append追加到AOF缓冲区内；
2. AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作sync同步到磁盘的AOF文件中；
3. AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量；
4. Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的；

**AOF和RDB同时开启，系统默认取AOF的数据（数据不会存在丢失）**

* appendfsync always 始终同步，每次Redis的写入都会立刻记入日志；性能较差但数据完整性比较好
* appendfsync everysec 每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。
* appendfsync no redis不主动进行同步，把同步时机交给操作系统。

优势
~~~~~~~~~
* 备份机制更稳健，丢失数据概率更低。
* 可读的日志文本，通过操作AOF稳健，可以处理误操作。


劣势
~~~~~~~~~~~~~~~~
* 比起RDB占用更多的磁盘空间。
* 恢复备份速度要慢。
* 每次读写都同步的话，有一定的性能压力。
* 存在个别Bug，造成恢复不能。

主从复制
-------------------
主机数据更新后根据配置和策略， 自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主

* 读写分离，性能扩展
* 容灾快速恢复


Redis集群
------------------
Redis 集群实现了对Redis的水平扩容，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。
Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯，集群也可以继续处理命令请求。


好处
``````````
* 实现扩容
* 分摊压力
* 无中心配置相对简单

不足
```````````````
* 多键操作是不被支持的 
* 多键的Redis事务是不被支持的。lua脚本不被支持
* 由于集群方案出现较晚，很多公司已经采用了其他的集群方案，
  而代理或者客户端分片的方案想要迁移至redis cluster，需要整体迁移而不是逐步过渡，复杂度较大。



Redis应用问题解决
------------------------
缓存穿透
```````````````
问题描述
~~~~~~~~~~~~~~~~~~~~~~~~~
key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会压到数据源，从而可能压垮数据源。
比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。
 

解决方案
~~~~~~~~~~~~~~~~~~~~
一个一定不存在缓存及查询不到的数据，由于缓存是不命中时被动写的，并且出于容错考虑，
如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

解决方案：

1. 对空值缓存：如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，
   设置空结果的过期时间会很短，最长不超过五分钟
2. 设置可访问的名单（白名单）：使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，
   每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问。
3. 采用布隆过滤器：(布隆过滤器（Bloom Filter）是1970年由布隆提出的。
   它实际上是一个很长的二进制向量(位图)和一系列随机映射函数（哈希函数）。
   布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。)
   将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被 这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。
4. 进行实时监控：当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务

缓存击穿
```````````````````
问题描述
~~~~~~~~~~~~~~~~~~~~~
key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，
这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
 

解决方案
~~~~~~~~~~~~~~~~
key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题。

解决问题：

1. 预先设置热门数据：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长
2. 实时调整：现场监控哪些数据热门，实时调整key的过期时长
3. 使用锁：
   - 就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db。
   - 先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key
   - 当操作返回成功时，再进行load db的操作，并回设缓存,最后删除mutex key；
   - 当操作返回失败，证明有线程在load db，当前线程睡眠一段时间再重试整个get缓存的方法。


缓存雪崩
`````````````````````
问题描述
~~~~~~~~~~~~~~~~~~~
key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，
这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，前者则是某一个key
 

解决方案
~~~~~~~~~~~~~~~~~~~~~~
缓存失效时的雪崩效应对底层系统的冲击非常可怕！

解决方案：

1. 构建多级缓存架构：nginx缓存 + redis缓存 +其他缓存（ehcache等）
2. 使用锁或队列：用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况
3. 设置过期标志更新缓存：记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。
4. 将缓存失效时间分散开：比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。



