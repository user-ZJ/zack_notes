大模型推理框架
====================================

+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
|    框架     |                          地址                          |                                             说明                                             |
+=============+========================================================+==============================================================================================+
| llama.cpp   | https://github.com/ggerganov/llama.cpp                 | 支持CPU和GPU，但只有encoder层运行在GPU上，embed、head、norm层仍运行在CPU上                   |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| llama.onnx  | https://github.com/tpoisonooo/llama.onnx               | 导出的onnx在cpu上正常运行，                                                                  |
|             |                                                        | 但onnx转tensorrt后数据不一致：https://github.com/NVIDIA/TensorRT/issues/2928                 |
|             |                                                        | chatglm实现https://github.com/vllm-project/vllm/pull/649                                     |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| ChatGLM-MNN | https://github.com/wangzhaode/ChatGLM-MNN              | 一个基于 MNN 的 ChatGLM-6B C++ 推理实现，支持根据显存大小自动分配计算任务给 GPU 和 CPU       |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| deepspeed   | https://www.deepspeed.ai/tutorials/inference-tutorial/ |                                                                                              |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| lyraChatGLM | https://huggingface.co/TMElyralab/lyraChatGLM          | 对 ChatGLM-6B 进行推理加速，最高可以实现 9000+ tokens/s 的推理速度                           |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| JittorLLMs  | https://github.com/Jittor/JittorLLMs                   | 目前支持了4种大模型：ChatGLM大模型；鹏程盘古大模型；BlinkDL的ChatRWKV；国外Meta的LLaMA大模型 |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| InferLLM    | https://github.com/MegEngine/InferLLM                  | 基于llama.cpp修改版本，只支持CPU                                                             |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| vllm        | https://github.com/vllm-project/vllm                   | https://github.com/vllm-project/vllm/discussions/275                                         |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| chatglm.cpp | https://github.com/li-plus/chatglm.cpp                 |                                                                                              |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| Megatron-LM | https://github.com/NVIDIA/Megatron-LM                  | 支持张量并行                                                                                 |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+
| mlc-llm     | https://github.com/mlc-ai/mlc-llm                      |                                                                                              |
+-------------+--------------------------------------------------------+----------------------------------------------------------------------------------------------+


https://mp.weixin.qq.com/s/xIbNSAI9cKGIA19yZhIEgg

https://mp.weixin.qq.com/s/e-3qkkAY3vpAnFlSNviotg